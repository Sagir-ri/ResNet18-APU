# ResNet18 神经网络加速器 (APU) 项目

## 项目概述

本项目实现了一个专用的 ResNet18 神经网络硬件加速器 (APU)，旨在高效执行深度学习应用中的卷积运算。该加速器使用 SystemVerilog 构建，支持多种卷积类型，包括标准卷积和残差连接，专门针对 ResNet18 架构进行了优化。


### 网络层次结构
- **前处理层**: 数据预处理和格式转换
- **Layer1**: 包含多个卷积块，通道数保持为64
- **Layer2**: 包含残差连接 (CONV6 + CONV7)，通道数从64增加到128
- **Layer3**: 包含残差连接 (CONV6 + CONV7)，通道数从128增加到256
- **后处理**: 全局平均池化 (avgpool) 和 Softmax 输出

### Pingpong 存储架构
本 APU 采用了创新的 Pingpong 存储架构，其中：
- **A (ActSRAM)**: 输入激活值存储器
- **O (OutSRAM)**: 输出激活值存储器

#### 计算方向说明
- **A->O 方向**: 从 ActSRAM 读取输入数据，计算结果写入 OutSRAM
- **O->A 方向**: 从 OutSRAM 读取输入数据，计算结果写入 ActSRAM

#### Pingpong 操作机制
- **交替使用**: 每层计算完成后，ActSRAM 和 OutSRAM 的角色互换
- **无缝流水**: 一个存储器作为输入时，另一个同时准备接收输出
- **减少数据搬移**: 避免了额外的数据拷贝操作
- **提高吞吐量**: 实现了计算和数据传输的并行处理

### 残差连接设计
在 ResNet18 的残差块中：
- **主路径**: 通过卷积操作处理特征图
- **跳跃连接**: 利用 Pingpong 机制实现输入特征的直接传递
- **特征融合**: 在适当的时机将主路径和跳跃连接的结果相加

## 系统架构

APU 由多个关键组件组成，采用分层架构设计：

### 顶层模块 (`Top.sv`)
主要的集成模块，连接所有子系统并管理组件间的数据流，协调 Pingpong 操作。

### 核心组件

#### 1. AHB 总线接口 (`ahb_slave.sv`, `ahb_slave_top.sv`)
- **功能**: 提供 AHB (高级高性能总线) 从设备接口用于外部通信
- **特性**: 
 - 32位数据宽度
 - 仅支持字访问（不支持部分访问）
 - 无等待状态，简化操作
- **地址映射**: 处理内部 RAM 和控制寄存器的内存映射访问

#### 2. 地址映射 (`addr_map.sv`)
- **控制寄存器**:
 - `RAM_CTRL_ADDR` (0x2000): RAM 控制信号
 - `RAM_SEL_ADDR` (0x2004): RAM 选择
 - `APU_READY_ADDR` (0x2008): APU 就绪状态
 - `CPL_ADDR` (0x200C): 完成状态
- **内存映射**: 根据地址范围将访问路由到相应的存储模块

#### 3. 指令管理 (`WorkSheet.v`)
- **功能**: 存储和排序计算指令
- **容量**: 最多 16 条指令
- **操作**: 在计算过程中自动推进指令序列

#### 4. 控制单元 (`Ctrl.sv`)
- **目的**: 主计算控制器，解码指令并协调数据流
- **Pingpong 控制**: 管理 ActSRAM 和 OutSRAM 之间的角色切换
- **支持的操作**:
 - 标准卷积 (操作码 00)
 - 残差卷积 (操作码 01)
- **指令格式**: `{opcode[2], kernelSize[2], logInHW[3], logInC[4], logOutC[4], stride1[2], stride2[2], wAddr[8], bnAddr[5]}`

#### 5. 存储子系统

##### 特征处理器 (`template_FeatureProcessor.sv`)
- **ActSRAM**: 输入激活值存储器 (A)
- **OutSRAM**: 输出激活值存储器 (O)
- **特性**:
 - 1024 × 64位存储器组织
 - 支持 1×1 和 3×3 卷积核
 - 边界像素自动填充
 - **Pingpong 机制**: 支持 A->O 和 O->A 双向数据流

##### 输入缓冲器 (`InBuf.sv`)
- **目的**: 管理激活值存储器和计算核心间的数据流
- **特性**:
 - 双输入多路复用器支持乒乓操作
 - 残差连接的常驻数据存储
 - 填充的零掩码
 - **Pingpong 支持**: 根据计算方向选择正确的输入源

##### RAM 多路复用器 (`ram_mux.sv`)
- **功能**: 将 AHB 访问路由到相应的存储模块
- **支持的 RAM**:
 - 指令 RAM (4位地址, 32位数据)
 - 输入/输出 RAM (10位地址, 64位数据)
 - 卷积权重 RAM (8位地址, 64位数据)
 - 批归一化 RAM (5位地址, 13位数据)

#### 6. 计算引擎

##### 计算核心组 (`ComputeCoreGroup.sv`)
- **架构**: 64 个并行计算核心
- **每个核心的组件**:
 - 权重 SRAM (256 × 64位)
 - 数据暂存的权重缓冲器
 - 64路 1位乘法器阵列
 - 6级加法树
 - 支持多种操作模式的累加器

##### SIMD 单元 (`SIMD.v`)
- **目的**: 批归一化和激活函数
- **配置**: 64 通道 × 13位比较阈值
- **操作**: 与存储阈值的并行比较

### 支持的 ResNet18 卷积配置

加速器支持以下卷积类型：

1. **Conv1**: 64→64 通道, 32×32 特征图, 3×3 核, 步长 1 (A->O)
2. **Conv2**: 64→128 通道, 32×32→16×16, 3×3 核, 步长 2 (O->A)
3. **Conv3**: 128→128 通道, 16×16 特征图, 3×3 核, 步长 1 (A->O)
4. **Conv4**: 128→256 通道, 16×16→8×8, 3×3 核, 步长 2 (O->A)
5. **Conv5**: 256→256 通道, 8×8 特征图, 3×3 核, 步长 1 (A->O)
6. **Conv6**: 残差连接 (Conv3 + 恒等映射)
7. **Conv7**: 残差连接 (Conv5 + 恒等映射)

### ResNet18 特殊支持

- **Pingpong 残差连接**: 利用双存储器结构实现高效的残差连接
- **批归一化**: 集成的 SIMD 单元处理批归一化操作
- **激活函数**: 硬件实现的 ReLU 激活
- **跳跃连接**: 通过 Pingpong 机制自动处理残差块中的跳跃连接

## Pingpong 操作流程

### 标准卷积流程
1. **第1层**: A->O (从 ActSRAM 读取，结果写入 OutSRAM)
2. **第2层**: O->A (从 OutSRAM 读取，结果写入 ActSRAM)
3. **第3层**: A->O (循环继续)

### 残差连接流程
1. **主路径**: 按标准 Pingpong 流程处理
2. **跳跃连接**: 从前一层的存储器直接读取原始特征
3. **特征融合**: 将主路径和跳跃连接结果相加后写入目标存储器

## 使用方法

### 编程模型

1. **初始化系统**: 通过 AHB 设置 RAM 控制寄存器
2. **加载数据**: 将输入激活值写入 ActSRAM
3. **配置层**: 将权重和偏置参数写入相应的 RAM
4. **编程指令**: 将指令序列写入指令 RAM
5. **开始计算**: 设置 APU 就绪标志
6. **Pingpong 执行**: 系统自动管理 A->O 和 O->A 的切换
7. **等待完成**: 监控中断信号
8. **读取结果**: 从最终的输出存储器提取结果

### 指令格式

指令为 32位值，包含以下字段：
[31:30] opcode     - 操作类型 (00: 卷积, 01: 残差)
[29:28] kernelSize - 核大小 (3 表示 3×3)
[27:25] logInHW    - 输入高度/宽度的对数
[24:21] logInC     - 输入通道数的对数
[20:17] logOutC    - 输出通道数的对数
[16:15] stride1    - 主步长
[14:13] stride2    - 辅助步长（用于残差）
[12:5]  wAddr      - 权重地址偏移
[4:0]   bnAddr     - 批归一化地址偏移

### 存储器布局

- **ActSRAM (A)**: 1024 × 64位 - Pingpong 存储器之一
- **OutSRAM (O)**: 1024 × 64位 - Pingpong 存储器之二
- **权重 RAM**: 64个 RAM × 256 × 64位
- **批归一化 RAM**: 64个 RAM × 32 × 13位
- **指令 RAM**: 16 × 32位

## ResNet18 测试

项目包含一个全面的测试平台 (`tb_top.v`)，可以：
- 加载完整的 ResNet18 网络参数
- 执行端到端的 ResNet18 推理
- 验证 Pingpong 机制的正确性
- 测试残差连接的正确性
- 支持完整的三层网络架构

### 测试数据格式
- 输入激活值：二进制格式文件
- 权重文件：按 ResNet18 层组织的二进制格式文件
  - `layer1.0.conv1.txt`, `layer1.0.conv2.txt`
  - `layer1.1.conv1.txt`, `layer1.1.conv2.txt`
  - `layer2.0.conv1.txt`, `layer2.0.conv2_combined.txt`
  - `layer2.1.conv1.txt`, `layer2.1.conv2.txt`
  - `layer3.0.conv1.txt`, `layer3.0.conv2_combined.txt`
  - `layer3.1.conv1.txt`, `layer3.1.conv2.txt`
- 批归一化参数：组合阈值文件
  - `layer*.bn*_combined.txt`

## 性能特征

- **计算吞吐量**: 每周期 64 个并行乘加运算
- **存储器带宽**: Pingpong 架构实现的高效内存利用
- **延迟**: 流水线操作，可配置累加模式
- **精度**: 1位权重，多位激活值，12位中间结果
- **Pingpong 优势**: 零拷贝数据传输，提高整体性能

## 文件组织
├── Top.sv                           # 顶层集成 (Pingpong 控制)
├── ahb_slave*.sv                    # AHB 总线接口
├── addr_map.sv                      # 地址解码器
├── ram_mux.sv                       # 存储器多路复用器
├── WorkSheet.v                      # 指令排序器
├── Ctrl.sv                          # 主控制器 (Pingpong 逻辑)
├── template_FeatureProcessor.sv     # 激活值存储器 (A & O)
├── InBuf.sv                         # 输入缓冲器 (Pingpong 支持)
├── ComputeCoreGroup.sv             # 计算引擎
├── SIMD.v                          # 批归一化
├── tb_top.v                        # ResNet18 测试平台
└── param_files/                    # ResNet18 参数文件目录
├── input_binary.txt
├── layer*.conv*.txt
├── layer*.bn*_combined.txt
└── data_out.txt

## 系统要求

- 兼容 SystemVerilog 的仿真器
- ResNet18 权重和测试数据的存储器初始化文件
- PYNQ板？

## ResNet18 Pingpong 特性

该加速器专为高效执行 ResNet18 二值神经网络而设计，具有以下特点：

- **完整的 ResNet18 支持**: 实现了标准 ResNet18 的所有层
- **Pingpong 架构**: A (ActSRAM) 和 O (OutSRAM) 交替作为输入输出
- **残差连接**: 利用 Pingpong 机制实现高效的跳跃连接和残差学习
- **批归一化**: 集成的批归一化处理单元
- **零拷贝传输**: Pingpong 机制避免了额外的数据搬移
- **流水线处理**: 多级流水线提高整体吞吐量
- **灵活的配置**: 支持不同的特征图尺寸和通道数

### Pingpong 优势

1. **内存效率**: 两个存储器交替使用，避免数据冗余
2. **计算连续性**: 一个存储器输出时，另一个同时准备输入
3. **残差实现**: 天然支持 ResNet 的跳跃连接结构
4. **带宽优化**: 减少内存访问冲突，提高带宽利用率

这个 APU 能够完成从输入图像到最终分类结果的完整 ResNet18 推理过程，通过创新的 Pingpong 存储架构为边缘计算和嵌入式 AI 应用提供了高效的硬件解决方案。
